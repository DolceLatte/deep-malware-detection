import os

import torch
from torch import optim
from tqdm.auto import tqdm

from utils import get_accuracy, plot_train_history


def train(
    model,
    train_loader,
    val_loader,
    device,
    save_title,
    patience=2,
    num_epochs=10,
    verbose=True,
):
    loss_history = []
    acc_history = []
    criterion = torch.nn.BCEWithLogitsLoss()
    optimizer = optim.Adam(model.parameters())
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, "max", patience=patience
    )
    model.train()
    for epoch in range(1, num_epochs + 1):
        loss_avg = 0
        for i, (inputs, labels) in enumerate(tqdm(train_loader, leave=False), start=1):
            inputs = inputs.to(device)
            labels = labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            loss_avg += loss.item()
            if verbose and i % 100 == 0:
                tqdm.write(
                    f"Epoch [{epoch}/{num_epochs}], "
                    f"Batch [{i}/{len(train_loader)}], "
                    f"Loss: {loss:.4f}"
                )
        loss_history.append(loss / i)
        accuracy = get_accuracy(model, val_loader, device)
        acc_history.append(accuracy)
        scheduler.step(accuracy)
        torch.save(
            model.state_dict(),
            os.path.join("weights", f"{save_title}_{epoch}_{int(accuracy)}.pt"),
        )
    plot_train_history(loss_history, acc_history, save_title)
