import torch
import torch.nn.functional as F
from torch import nn


class MalConvBase(nn.Module):
    def __init__(
        self, embed_dim, max_len, out_channels, window_size, dropout,
    ):
        super(MalConvBase, self).__init__()
        self.embed = nn.Embedding(257, embed_dim)
        self.dropout = nn.Dropout(dropout)
        self.conv = nn.Conv1d(
            in_channels=embed_dim,
            out_channels=out_channels * 2,
            kernel_size=window_size,
            stride=window_size,
        )
        self.fc = nn.Linear(out_channels, 1)

    def forward(self, x):
        batch_size, seq_len = x.size(0), x.size(1)
        embedding = self.dropout(self.embed(x))
        conv_in = embedding.permute(0, 2, 1)
        conv_out = self.conv(conv_in)
        glu_out = F.glu(conv_out, dim=1)
        values, indices = glu_out.max(dim=-1)
        output = self.fc(values).squeeze(1)
        return output


class MalConvPlus(nn.Module):
    def __init__(
        self, embed_dim, max_len, out_channels, window_size, dropout,
    ):
        super(MalConvPlus, self).__init__()
        self.tok_embed = nn.Embedding(257, embed_dim)
        self.pos_embed = nn.Embedding(max_len, embed_dim)
        self.dropout = nn.Dropout(dropout)
        self.conv = nn.Conv1d(
            in_channels=embed_dim,
            out_channels=out_channels * 2,
            kernel_size=window_size,
            stride=window_size,
        )
        self.fc = nn.Linear(out_channels, 1)

    def forward(self, x):
        batch_size, seq_len = x.size(0), x.size(1)
        tok_embedding = self.tok_embed(x)
        pos = torch.arange(seq_len).unsqueeze(0).repeat(batch_size, 1)
        pos_embedding = self.pos_embed(pos)
        embedding = self.dropout(tok_embedding + pos_embedding)
        conv_in = embedding.permute(0, 2, 1)
        conv_out = self.conv(conv_in)
        glu_out = F.glu(conv_out, dim=1)
        values, indices = glu_out.max(dim=-1)
        output = self.fc(values).squeeze(1)
        return output


class RCNN(nn.Module):
    def __init__(
        self,
        embed_dim,
        out_channels,
        window_size,
        module,
        hidden_size,
        num_layers,
        dropout,
    ):
        super(RCNN, self).__init__()
        assert module.__name__ in {
            "GRU",
            "LSTM",
        }, "`module` must be one of `torch.nn.GRU` or `torch.nn.LSTM`"
        self.embed = nn.Embedding(257, embed_dim)
        self.conv = nn.Conv1d(
            in_channels=embed_dim,
            out_channels=out_channels,
            kernel_size=window_size,
            stride=window_size,
        )
        self.rnn = module(
            input_size=out_channels, hidden_size=hidden_size, num_layers=num_layers,
        )
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(num_layers * hidden_size, 1)

    def forward(self, x):
        batch_size = x.size(0)
        embedding = self.dropout(self.embed(x))
        conv_in = embedding.permute(0, 2, 1)
        conv_out = self.conv(conv_in)
        conv_out = conv_out.permute(2, 0, 1)
        try:
            _, (hidden, _) = self.rnn(conv_out)
        except ValueError:
            _, hidden = self.rnn(conv_out)
        hidden = hidden.reshape(batch_size, -1)
        output = self.fc(hidden).squeeze(1)
        return output


class ResRCNN(nn.Module):
    def __init__(
        self,
        embed_dim,
        out_channels,
        window_size,
        module,
        hidden_size,
        num_layers,
        dropout,
    ):
        super(ResRCNN, self).__init__()
        assert module.__name__ in {
            "GRU",
            "LSTM",
        }, "`module` must be one of `torch.nn.GRU` or `torch.nn.LSTM`"
        self.rnn_type = module.__name__
        self.embed = nn.Embedding(257, embed_dim)
        self.conv = nn.Conv1d(
            in_channels=embed_dim,
            out_channels=out_channels,
            kernel_size=window_size,
            stride=window_size,
        )
        self.rnn = module(
            input_size=out_channels, hidden_size=hidden_size, num_layers=num_layers,
        )
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(out_channels + num_layers * hidden_size, 1)

    def forward(self, x):
        batch_size = x.size(0)
        embedding = self.dropout(self.embed(x))
        conv_in = embedding.permute(0, 2, 1)
        conv_out = self.conv(conv_in)
        values, indices = conv_out.max(dim=-1)
        conv_out = conv_out.permute(2, 0, 1)
        try:
            _, (hidden, _) = self.rnn(conv_out)
        except ValueError:
            _, hidden = self.rnn(conv_out)
        hidden = hidden.reshape(batch_size, -1)
        fc_in = torch.cat((hidden, values), dim=-1)
        output = self.fc(fc_in).squeeze(1)
        return output


class AttentionRCNN(nn.Module):
    def __init__(
        self,
        embed_dim,
        out_channels,
        window_size,
        module,
        hidden_size,
        num_layers,
        dropout,
    ):
        super(AttentionRCNN, self).__init__()
        assert module.__name__ in {
            "GRU",
            "LSTM",
        }, "`module` must be one of `torch.nn.GRU` or `torch.nn.LSTM`"
        self.rnn_type = module.__name__
        self.embed = nn.Embedding(257, embed_dim)
        self.conv = nn.Conv1d(
            in_channels=embed_dim,
            out_channels=out_channels,
            kernel_size=window_size,
            stride=window_size,
        )
        self.rnn = module(
            input_size=out_channels, hidden_size=hidden_size, num_layers=num_layers,
        )
        seq_len = 4096 // window_size
        self.mask = nn.Parameter(nn.init.kaiming_uniform_(torch.empty(seq_len, 1, 1)))
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(num_layers * hidden_size, 1)

    def forward(self, x):
        batch_size = x.size(0)
        embedding = self.dropout(self.embed(x))
        conv_in = embedding.permute(0, 2, 1)
        conv_out = self.conv(conv_in)
        values, indices = conv_out.max(dim=-1)
        conv_out = conv_out.permute(2, 0, 1)
        rnn_out, _ = self.rnn(conv_out)
        attention = (self.mask * rnn_out).mean(dim=0)
        output = self.fc(attention).squeeze(1)
        return output


# class TransformerNet(nn.Module):
#     pass


# https://towardsdatascience.com/bert-text-classification-using-pytorch-723dfb8b6b5b
# https://machinelearningmastery.com/cnn-long-short-term-memory-networks/
# https://github.com/bamtercelboo/cnn-lstm-bilstm-deepcnn-clstm-in-pytorch/blob/master/models/model_CLSTM.py
